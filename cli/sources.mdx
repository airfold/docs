---
title: 'Sources'
description: 'Bring your data into Airfold'
icon: "database"
---

Data is ingested into sources directly through Airfold's Ingest API or by a [pipe](/cli/pipes).

## Creation
Define the schema for your source in a YAML file:

```yaml sales_calls.yaml
name: sales_calls
description: sales call transcripts
cols:
  ID: UUID
  Transcript: String
settings:
  engine: MergeTree()
  order_by: '`ID`'
  partition_by: tuple()
```

<br />

### Properties

<ResponseField name="type" type="string">
  Type of source: `Table` or `AITable`, see more on [AI table](/cli/ai_tables) (Optional)
</ResponseField>
<ResponseField name="name" type="string">
  Name of source
</ResponseField>
<ResponseField name="description" type="string">
  A brief overview of the source's content or purpose (optional)
</ResponseField>
<ResponseField name="cols" type="{name: type}" required>
  Defines the schema of the source as a list of columns where each column name is a key and its data type is the value (see [Data Types](https://clickhouse.com/docs/en/sql-reference/data-types))
</ResponseField>
<ResponseField name="settings" type="string | {key: value} | array">
  [ClickHouse table configuration](https://clickhouse.com/docs/en/sql-reference/statements/create/table) for the source, which can include `ORDER BY`, `PARTITION BY`, Table Engine, etc. The settings can be a String, a key-value pair, or an array comprising either or both. Optional.
</ResponseField>

## Push
Push sources to your [workspace](/cli/workspaces) using the [CLI command](/cli/cli_reference) or [API](/api-reference/workspace/push).<br />

### CLI

For example, to push `sales_calls.yaml`, run:
```bash
af push sales_calls.yaml
```

### Ingest API
We can also use [Ingest API](/api-reference/ingest/ingest):

The Ingest API supports the following formats:
- NDJSON
- CSV
- Parquet

For example, ingesting NDJSON is as simple as:
```bash
curl --request POST \
  --url https://api.airfold.co/v1/sales_analysis/{source} \
  --header 'Authorization: Bearer <key>' \
  --header 'Content-Type: application/json' \
  --data '[
  { "id": 123, "name": "Sarah"},
  { "id": 456, "name": "Alex"}
]'
```

<Note>
### Rate Limits
The Ingest API is rate limited to 1000 events/sec per source. If you need to ingest more events, please [contact us](https://www.airfold.co).
</Note>


## `_errors` Table
Every workspace has an associated `_errors` source table, which contains all errors that occurred during ingestion (e.g.: if a row failed to be ingested due to schema mismatch).

This way, the whole ingestion process is uninterrupted and the error can be fixed later.

`_errors` is treated like any other source, so it can be queried, filtered, and joined with other sources.

For example, we can find the most common errors by source:
```sql
SELECT source, COUNT(*) AS count
FROM _errors
GROUP BY source
ORDER BY count DESC
```