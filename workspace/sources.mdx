---
title: 'Source'
description: 'Bring your data into Airfold'
icon: "database"
---

Akin to tables in a database, sources store data according to a defined schema.

All the workspace data lives inside sources, which can be queried, filtered, aggregated, and joined using SQL.

Data is ingested into sources directly through Airfold's Ingest API or by a [pipe](/workspace/pipes).

Additionally, sources can be enhanced into **AI sources** for transforming unstructured data into structured formats, unlocking powerful analytical potential.

## Creation
Define the schema for your source in a YAML file:
<CodeGroup>
```yaml sales_calls.yaml
type: Table
name: sales_calls
description: sales call transcripts
cols:
  ID: UUID
  Transcript: String
settings:
  engine: MergeTree()
  order_by: '`ID`'
  partition_by: tuple()
```

```yaml ai_sales_calls.yaml
type: AITable
name: ai_sales_calls
description: AI enhanced version of sales_calls
ai_cols:
  - name: successful
    type: Nullable(Bool)
    description: Whether this call was successful (which is defined as successfully
      setting up a follow up call). If the follow up scheduling is successful, the
      call should include an explicit date/time for the call.
    default_value: '""'
    using:
      - Transcript
  - name: competitors_mentioned
    type: Array(String)
    description: Who are the competitors mentioned (if any)?
    default_value: '"N/A"'
    using:
      - Transcript
  - name: features_mentioned
    type: Array(Enum('Customizable Templates', 'Inventory Management', 'Marketing
      Automation', 'Customer Support Integration', 'Social Media Integration', 'None'))
    description: Which features are mentioned in the call?
    default_value: '["None"]'
    using:
      - Transcript
cols:
  ID: UUID
  Transcript: String
```
</CodeGroup>

<br />

### Properties

<ResponseField name="type" type="string">
  Type of source: `Table` or `AITable`
</ResponseField>
<ResponseField name="name" type="string">
  Name of source
</ResponseField>
<ResponseField name="description" type="string">
  A brief overview of the source's content or purpose (optional)
</ResponseField>
<ResponseField name="ai_cols" type="array">
  Columns to be filled by the AI source.
  <Expandable title="ai_cols Properties" defaultOpen="true">
    <ResponseField name="name" type="string" required>
      The name of the column.
    </ResponseField>
    <ResponseField name="type" type="string" required>
      The data type of the column.
    </ResponseField>
    <ResponseField name="description" type="string" required>
      A description of the column (see [Data Types](https://clickhouse.com/docs/en/sql-reference/data-types)).
    </ResponseField>
    <ResponseField name="default_value" type="string">
      The default value of the column.
    </ResponseField>
    <ResponseField name="using" type="array" required>
      The columns to use in the AI transformation.
    </ResponseField>
  </Expandable>
</ResponseField>
<ResponseField name="cols" type="{name: type}" required>
  Defines the schema of the source as a list of columns where each column name is a key and its data type is the value (see [Data Types](https://clickhouse.com/docs/en/sql-reference/data-types))
</ResponseField>
<ResponseField name="settings" type="string | {key: value} | array">
  [ClickHouse table configuration](https://clickhouse.com/docs/en/sql-reference/statements/create/table) for the source, which can include `ORDER BY`, `PARTITION BY`, Table Engine, etc. The settings can be a String, a key-value pair, or an array comprising either or both. Optional.
</ResponseField>

## Push
Push sources to your [workspace](/workspace/workspaces) using the [CLI command](/reference/cli) or [API](/api-reference/workspace/push).<br />

### CLI

For example, to push `sales_calls.yaml`, run:
```bash
af push sales_calls.yaml
```

### Ingest API
We can also use [Ingest API](/api-reference/ingest/ingest):

The Ingest API supports the following formats:
- NDJSON
- CSV
- Parquet

For example, ingesting NDJSON is as simple as:
```bash
curl --request POST \
  --url https://api.airfold.co/v1/sales_analysis/{source} \
  --header 'Authorization: Bearer <key>' \
  --header 'Content-Type: application/json' \
  --data '[
  { "id": 123, "name": "Sarah"},
  { "id": 456, "name": "Alex"}
]'
```

<Note>
### Rate Limits
The Ingest API is rate limited to 1000 events/sec per source. If you need to ingest more events, please [contact us](https://www.airfold.co).
</Note>


## `_errors` Table
Every workspace has an associated `_errors` source table, which contains all errors that occurred during ingestion (e.g.: if a row failed to be ingested due to schema mismatch).

This way, the whole ingestion process is uninterrupted and the error can be fixed later.

`_errors` is treated like any other source, so it can be queried, filtered, and joined with other sources.

For example, we can find the most common errors by source:
```sql
SELECT source, COUNT(*) AS count
FROM _errors
GROUP BY source
ORDER BY count DESC
```